<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kyla Franks | My FYP</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@500&family=Poppins:wght@300;500&display=swap" rel="stylesheet">
</head>
<body>
    <div class="overlay"></div>

    <nav>

        <!-- Social Icons Section (Left Side) -->
        <div class="social-icons">
            <a href="https://github.com/KylaF8" target="_blank" class="github-icon">
                <i class="fa-brands fa-github"></i>
            </a>
            <a href="https://www.linkedin.com/in/kylafranks" target="_blank" class="linkedin-icon">
                <i class="fa-brands fa-linkedin"></i>
            </a>
        </div>

        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="Project.html">My FYP</a></li>
        </ul>
    </nav>

        <div class="text-box">
            <h1>AML & the risk it poses to AI Security</h1>
            <h2>Adversarial Machine Learning (AML) poses a significant threat to AI security, but the development of robust defence mechanisms exist which need to be configured to match certain scenarios.</h2>
            <p>AI security is an interdisciplinary field focused on preventing accidents, misuse, or harmful consequences arising from artificial intelligence systems. These systems range from reactive machines to self-aware models. However, they face significant risks, particularly in the area of data safety, which is crucial for machine learning.
                The swift proliferation of artificial intelligence (AI) technology has transformed the real world and industries, from autonomous vehicles and technology to healthcare and more. However, the ever-growing dependence on machine learning (ML) models creates a litany of vulnerabilities to adversarial risks, where malicious adversaries or actors are able to exploit and manipulate input data that is in training, in order to mislead and deceive the systems. Such a vulnerability highlights the importance for Adversarial Machine Learning (AML), a field that focused on finding through investigation any of these threats, to mitigate them and create more robust and reliable systems.
                AML explores adversarial attacksâ€”data poisoning, evasions, or model extraction, and how these exploit the vulnerabilities of ML models, and how to further protect the systems provenance and integrity. Attacks such as these could lead to many consequential consequences, especially in sensitive cases where it is vital to keep the systems secure and reliable, an example being medical diagnostics being misclassified. This report divulges into the variety of methods and concepts surround AML, the role it has in bettering AI security, the evolution of AML, and more, all aiming to mitigate the threats of adversaries in this ML-revolutionised world.
                As AML evolves and develops, the contributions it has are pivotal when it comes to guaranteeing AI systems are to remain robust and dependable. The nuances of adversarial defences and attacks are investigated further through various scholar-published papers and reports, all aiding in the goal to create a report that provides well-developed insights into the challenges at present, and the potential future plans in AML research. Therefore, highlighting the significance in the wider expanse of AI security and integrity.
            </p>
            <!-- <div class="buttons">
                <a href="index.html" class="btn primary-btn">Home Page</a>
            </div> -->
        </div>
    </div>

    <footer>
        <p>&copy; 2024 Kyla Franks.</p>
    </footer>

</body>
</html>