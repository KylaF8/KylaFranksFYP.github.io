<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Kyla Franks | My FYP</title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css2?family=Playfair+Display:wght@500&family=Poppins:wght@300;500&display=swap" rel="stylesheet">
</head>
<body>
    <div class="overlay"></div>

    <nav>
        <div class="social-icons">
            <a href="https://github.com/KylaF8" target="_blank" class="github-icon">
                <i class="fa-brands fa-github"></i>
            </a>
            <a href="https://www.linkedin.com/in/kylafranks" target="_blank" class="linkedin-icon">
                <i class="fa-brands fa-linkedin"></i>
            </a>
        </div>
        <ul>
            <li><a href="index.html">Home</a></li>
            <li><a href="Project.html">My FYP</a></li>
        </ul>
    </nav>
    

        <div class="text-box">
            <h2>Adversarial Machine Learning (AML) poses a significant threat to the security of AI-based systems. The proposed defence mechanisms need to be configured to match specific scenarios</h2>
            <blockquote class="quote">
                "Adversarial Machine Learning (AML) poses a significant threat to AI security, 
                but the development of robust defence mechanisms exist which need to be 
                configured to match certain scenarios."
            </blockquote>            
            <!-- <p>AI security is an interdisciplinary field focused on preventing accidents, misuse, or harmful consequences arising from artificial intelligence systems. These systems range from reactive machines to self-aware models. However, they face significant risks, particularly in the area of data safety, which is crucial for machine learning.
                The swift proliferation of artificial intelligence (AI) technology has transformed the real world and industries, from autonomous vehicles and technology to healthcare and more. However, the ever-growing dependence on machine learning (ML) models creates a litany of vulnerabilities to adversarial risks, where malicious adversaries or actors are able to exploit and manipulate input data that is in training, in order to mislead and deceive the systems. Such a vulnerability highlights the importance for Adversarial Machine Learning (AML), a field that focused on finding through investigation any of these threats, to mitigate them and create more robust and reliable systems.
                AML explores adversarial attacksâ€”data poisoning, evasions, or model extraction, and how these exploit the vulnerabilities of ML models, and how to further protect the systems provenance and integrity. Attacks such as these could lead to many consequential consequences, especially in sensitive cases where it is vital to keep the systems secure and reliable, an example being medical diagnostics being misclassified. This report divulges into the variety of methods and concepts surround AML, the role it has in bettering AI security, the evolution of AML, and more, all aiming to mitigate the threats of adversaries in this ML-revolutionised world.
                As AML evolves and develops, the contributions it has are pivotal when it comes to guaranteeing AI systems are to remain robust and dependable. The nuances of adversarial defences and attacks are investigated further through various scholar-published papers and reports, all aiding in the goal to create a report that provides well-developed insights into the challenges at present, and the potential future plans in AML research. Therefore, highlighting the significance in the wider expanse of AI security and integrity. -->

                    <div class="container">
                        <ul>
                            <li><strong>AI security</strong> is an interdisciplinary field focused on preventing accidents, misuse, and harmful consequences in AI systems.</li>
                            <li><strong>Machine Learning (ML) vulnerabilities</strong> make AI systems susceptible to adversarial attacks, where input data is manipulated to deceive models.</li>
                            <li><strong>Adversarial Machine Learning (AML)</strong> focuses on investigating and mitigating such attacks to improve the robustness of ML models.</li>
                            <li><strong>Examples of risks:</strong> Data poisoning, model evasion, model extraction, and inference attacks.</li>
                            <li><strong>Importance:</strong> Critical in sectors like healthcare, where misclassification could have severe consequences.</li>
                        </ul>
                    </div>
            </p>
            <!-- <div class="buttons">
                <a href="index.html" class="btn primary-btn">Home Page</a>
            </div> -->
        </div>
    </div>

    <section class="image-gallery">
        <div class="image-card">
            <img src="images/AI.jpg" alt="Abstract Image 2">
        </div>
        <div class="image-card">
            <img src="images/AdversarialTrainingSchematic.webp" alt="Abstract Image 1">
        </div>
        <div class="image-card">
            <img src="images/AI2.jpg" alt="Abstract Image 3">
        </div>
    </section>

    <footer>
        <p>&copy; 2024 Kyla Franks.</p>
    </footer>

</body>
</html>